{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5264d5f-99ac-4858-beb2-dcab892e1225",
   "metadata": {},
   "source": [
    "# 1주차 HomeWork\n",
    "- Bucketing 이해 및 구현\n",
    "- NSMC 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d84ff-9ad3-41e5-9abd-166a6d13f11f",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e54f4e-a0bf-48e2-9344-4dd3d4197329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34271963-7699-4a1a-9b69-60bb5dce5d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "sys.path.append('/root/nlp-with-transformers')\n",
    "from src.data import NSMCDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e66b64-43d8-4a08-8b03-7cf4d9ee20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset nsmc (/root/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc417166969459898d947040ad5d602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b0d6e66fbd4a69930d174f974aef3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-2d03d9ec85550652.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cd8f5c6dbd4fa78a7403131cc09ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719dfa3152554025a66f35c30ba1a613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-fa4cc0bdb164e8b3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eedd29cca564803a5f513afd07888fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = OmegaConf.load('conf/nsmc.yaml')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model.pretrained_model_name_or_path)\n",
    "dm = NSMCDataModule(tokenizer=tokenizer, **OmegaConf.to_container(config.data))\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dfe8fb-4c58-4235-b543-b7772d476c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_dir = '/root/model_safari'\n",
    "config.training.output_dir = f\"{model_base_dir}/{config.model.pretrained_model_name_or_path}-finetuned-nsmc\"\n",
    "config.training.logging_steps = len(dm.ds['train']) // config.training.per_device_train_batch_size\n",
    "training_args = TrainingArguments(**OmegaConf.to_container(config.training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd37a9-46bd-4fd8-bd16-15db506f33d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92da764-3b88-4b77-a897-9b450c4fcb72",
   "metadata": {},
   "source": [
    "### Bucketing에 따른 배치별 label 분포 차이 확인.\n",
    "* bucketing을 적용할 경우, 속도는 빨라지지만, 문장 길이에 따른 클래스 분포가 RandomSampling과 차이가 존재할 경우, 성능하락이 있을 수 있음.\n",
    "* 그래서 RandomSampler와 LengthGroupSampler의 미니배치의 비율 차이를 확인하는 것이 도움이 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb17ac2-48b6-484d-9848-5186a2ed6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data import RandomSampler\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.trainer_utils import seed_worker\n",
    "from transformers.trainer_pt_utils import LengthGroupedSampler\n",
    "\n",
    "from src.utils.dl_stats import aggregate_batch_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4508aecb-63aa-4320-bcb6-c39aa5236c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "generator.manual_seed(training_args.seed)\n",
    "data_collator = DataCollatorWithPadding(tokenizer,return_tensors='np')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab4158-fb04-445e-8b95-144703623a05",
   "metadata": {},
   "source": [
    "* length_group_sampler는 dataset의 index를 input의 길이를 기준으로 정렬하기 때문에 시간이 좀 걸림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06eabec4-ae06-488f-8137-e27d54c0bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 µs, sys: 4 µs, total: 55 µs\n",
      "Wall time: 64.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_sampler = RandomSampler(dm.ds['train'], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0122300a-30b9-46e1-81e7-a42c2f815c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 127 ms, total: 44.2 s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "length_group_sampler = LengthGroupedSampler(training_args.per_device_train_batch_size, dataset=dm.ds['train'], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78eea68e-c2eb-43fa-8729-e946812a3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampler\n",
    "rs_dl = DataLoader(\n",
    "            dm.ds['train'],\n",
    "            batch_size=training_args.per_device_train_batch_size,\n",
    "            sampler=random_sampler,\n",
    "            collate_fn=data_collator,\n",
    "            drop_last=True,\n",
    "            num_workers=training_args.dataloader_num_workers,\n",
    "            pin_memory=training_args.dataloader_pin_memory,\n",
    "            worker_init_fn=seed_worker,\n",
    "        )\n",
    "# length group sampler\n",
    "lg_dl = DataLoader(\n",
    "            dm.ds['train'],\n",
    "            batch_size=training_args.per_device_train_batch_size,\n",
    "            sampler=length_group_sampler,\n",
    "            collate_fn=data_collator,\n",
    "            drop_last=True,\n",
    "            num_workers=training_args.dataloader_num_workers,\n",
    "            pin_memory=training_args.dataloader_pin_memory,\n",
    "            worker_init_fn=seed_worker,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2c4df4-df55-4f04-a4ad-d8e87d24a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e16163a-54c5-4662-a014-bd1327525bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-02 05:46:31.028: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:75] Found unsupported HuggingFace version 4.25.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "[2023-02-02 05:46:31.116 ee7736cf838b:2818 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-02-02 05:46:31.284 ee7736cf838b:2818 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "rs_df = aggregate_batch_label_counts(rs_dl, dm.id2label)\n",
    "lg_df = aggregate_batch_label_counts(lg_dl, dm.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1a255-0f17-4041-902d-79e21c7c9f47",
   "metadata": {},
   "source": [
    "* 평균은 갖고 분산만 다름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "301bb15a-188f-45a1-82aa-1e4275bf5b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sampling\n",
      "31.91 ± 3.95\n",
      "LengthGroup Sampling\n",
      "31.91 ± 4.10\n"
     ]
    }
   ],
   "source": [
    "print('Random Sampling')\n",
    "print(f\"{rs_df['positive'].mean():.2f} ± {rs_df['positive'].std():.2f}\")\n",
    "print('LengthGroup Sampling')\n",
    "print(f\"{lg_df['positive'].mean():.2f} ± {lg_df['positive'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ab2af-3494-4ed6-b661-7f6048fdbbde",
   "metadata": {},
   "source": [
    "* 독립표본 t검증으로도 귀무가설 채택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e968710a-1b9c-4160-97ee-226f2df51714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.9941\n"
     ]
    }
   ],
   "source": [
    "stat, pv = ttest_ind(rs_df['positive'], lg_df['positive'])\n",
    "print(f\"p-value: {pv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed71d1-1c7e-461d-95cd-d1904f7073db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f732c3-a3e5-44a9-b605-9cbea5e11613",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd30caf7-a759-4e05-ad06-02e7bd5be3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred:EvalPrediction):\n",
    "    \"\"\"Get EvalPrediction and Calculate the metrics\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\":acc, \"f1\":f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261ce13d-9508-4440-912b-9d087b1ef83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_PROJECT'] = config.env['wandb']['WANDB_PROJECT']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.model.pretrained_model_name_or_path, \n",
    "    num_labels=dm.num_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "631bdb97-c37a-4fe0-a879-7155a679c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=dm.ds['train'],\n",
    "                  eval_dataset=dm.ds['validation'],\n",
    "                  data_collator=dm.get_collate_fn(),\n",
    "                  callbacks=[WandbCallback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1c172d-7fc3-4cb8-a617-faef16e08421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(training_args.group_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "533edd3a-bc71-4c44-a538-1082353683af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdatalama\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/nlp-with-transformers/notebooks/2/wandb/run-20230202_054757-0ifyefou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/datalama/lama-test/runs/0ifyefou\" target=\"_blank\">/root/model_safari/klue/bert-base-finetuned-nsmc</a></strong> to <a href=\"https://wandb.ai/datalama/lama-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/datalama/lama-test\" target=\"_blank\">https://wandb.ai/datalama/lama-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/datalama/lama-test/runs/0ifyefou\" target=\"_blank\">https://wandb.ai/datalama/lama-test/runs/0ifyefou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6681' max='6681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6681/6681 35:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.276700</td>\n",
       "      <td>0.243326</td>\n",
       "      <td>0.899867</td>\n",
       "      <td>0.899767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.228202</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.912267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.252896</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.913590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 6s, sys: 10min 55s, total: 38min 1s\n",
      "Wall time: 35min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rs_model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b9827d-d5f8-4115-bc81-08313ad2abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.group_by_length = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36034aff-ab77-47e2-8550-00615053586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=dm.ds['train'],\n",
    "                  eval_dataset=dm.ds['validation'],\n",
    "                  data_collator=dm.get_collate_fn(),\n",
    "                  callbacks=[WandbCallback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0221b32-c5a8-4947-90ba-be72b977bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6681' max='6681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6681/6681 15:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.905467</td>\n",
       "      <td>0.905450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.303188</td>\n",
       "      <td>0.906400</td>\n",
       "      <td>0.906393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.369119</td>\n",
       "      <td>0.907067</td>\n",
       "      <td>0.907054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 47s, sys: 2min 50s, total: 16min 37s\n",
      "Wall time: 15min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg_model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e183297-52ec-47ca-b443-6f96716f0235",
   "metadata": {},
   "source": [
    "* 결과\n",
    "  * 확실히 bucketing을 적용한 데이터가 더 빠르게 수렴하는 현상을 보임. (절반 이하)\n",
    "  * 물론 실험을 한번만 돌려서 확언하기는 어렵지만, bucketing을 적용한 경우, Validation loss가 빠르게 exploding하는 현상을 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab8afa-339a-4c3e-af27-35dc4b41f16c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
