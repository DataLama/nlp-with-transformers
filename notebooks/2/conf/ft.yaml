data:
  dataset_name: emotion # path in load_dataset
  padding: True
  truncation: True
  max_length: # max_seq_len
  num_workers: 0
  preprocessing_num_workers: 1
  
model:
  pretrained_model_name_or_path: "distilbert-base-uncased"
  
training:
  output_dir: # interpolation
  num_train_epochs: 3
  per_device_train_batch_size: 64
  per_device_eval_batch_size: 64
  learning_rate: 2e-5
  weight_decay: 0.01
  evaluation_strategy: epoch
  disable_tqdm: False
  logging_steps: # interpolation
  push_to_hub: False
  save_strategy: epoch
  load_best_model_at_end: True
  log_level: "error"
  report_to:
      - wandb

env:
  wandb: 
  # https://huggingface.co/docs/transformers/main_classes/callback#transformers.integrations.WandbCallback.setup 
    WANDB_PROJECT: lama-test # wandb project 이름.
    WANDB_LOG_MODEL: False
    WANDB_WATCH: False
    WANDB_DISABLED: False
    