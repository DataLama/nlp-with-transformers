{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e9ddff0-18a8-4c0d-8c23-5e845e5a119e",
   "metadata": {},
   "source": [
    "# 6. 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c065141-f6a1-4d23-9cff-6a6abf9d0fc9",
   "metadata": {},
   "source": [
    "## 6.1. The CNN/DailyMail Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fe000-d3d9-403d-8cbf-f675fe6b46c6",
   "metadata": {},
   "source": [
    "* 3.0.0은 익명화 처리를 하지않은 버전\n",
    "* 요약에서는 관례적으로 문장을 줄바꿈으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e953e4e2-42c6-4cd7-a5c9-f8bb8664ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb52b485040540608ab80aa6c6219289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b5f74-f807-4c28-bd51-e2ebb54fa82f",
   "metadata": {},
   "source": [
    "* article, highlights, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7862a31-e602-473a-a4fe-73d11eb88719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d58929b-adc0-4e0f-935f-a212affadc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[\"train\"][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d44edf-f209-45bb-95c3-ead5551d9f37",
   "metadata": {},
   "source": [
    "* 전체 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d529a331-d6a1-4464-8632-44b2f9e4c498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LAS VEGAS, Nevada (CNN)  -- Former football star O.J. Simpson will be held without bail after his arrest on robbery and assault charges, police announced late Sunday. Police released this mug shot of O.J. Simpson after his arrest. Simpson is accused of having directed several other men in an alleged armed robbery of sports memorabilia in a room at a Las Vegas hotel room. Las Vegas authorities said they have no information leading them to believe Simpson was carrying a firearm during the alleged incident at the Palace Station Hotel and Casino. Police said Simpson and other men burst into the room and walked out with the memorabilia, including some that was unrelated to Simpson, police said. \"We don\\'t believe that anyone was roughed up, but there were firearms involved,\" Lt. Clint Nichols told reporters. Nichols said the firearms were pointed at the victims. A reporter asked Nichols: Was \"O.J. was the boss in that room?\" Nichols responded, \"That is what we believe, yes.\"  Watch Simpson transferred Sunday in handcuffs » . The alleged victims were identified as Bruce Fromong, a sports memorabilia collector who described the incident as \"a home invasion-type robbery,\" and Alfred Beardsley, who has been quoted by celebrity Web site TMZ.com as saying that Simpson later apologized to him and told him he regretted the incident. Acting on a tip, police met over the weekend at McCarran International Airport with 46-year-old Walter Alexander, of Mesa, Arizona, who told them about the alleged robbery and validated the tipster\\'s information, Capt. James Dillon told reporters. Alexander was arrested Saturday night on two counts of robbery with a deadly weapon, two counts of assault with a deadly weapon, conspiracy to commit robbery and burglary with a deadly weapon. He was released on his own recognizance and returned to Mesa either Saturday night or early Sunday morning, Dillon said. In addition, investigators are seeking four other men they believe accompanied Simpson into the hotel room, Nichols said. Nichols said, \"There is a social relationship between the individuals that we identified and O.J. Simpson.\" Though Simpson is not accused of having brandished a gun himself, two firearms that police said were used were recovered early Sunday in one of three searches. Investigators would would not divulge where the weapons were found. Nichols dismissed an initial report that the men may have been off-duty police. \"There is no truth to that whatsoever,\" he said. \"That came as a result of some language that was used when the individuals burst into the room that led our victims to believe that they may have been police.\" Simpson, 60, has acknowledged taking some items that belonged to him, but he has denied that any weapons were involved. \"Whether the property belonged to Mr. Simpson or not is still in debate,\" Nichols said. \"We are still in the process of sorting that out.\" Nichols also said that some of the property taken had Simpson\\'s signature. But \"there was some other property taken as well,\" he said. \"I believe there were some Joe Montana cleats and some signed baseballs and other stuff.\" The latest charges against Simpson mean he faces the prospect of another prosecution, more than a decade after the June 1994 stabbing deaths of his ex-wife, Nicole Brown Simpson, and Ron Goldman. Simpson was acquitted of murder the following year. The trial riveted much of the United States. But in 1997, a jury found him liable for the deaths in a civil case brought by the Goldman family. Simpson was ordered to pay the families a total of $33.5 million for the deaths . Goldman had gone to Nicole Simpson\\'s Los Angeles home to return a pair of glasses the day of the slayings. Goldman\\'s sister, Kim Goldman, said she wasn\\'t surprised by the robbery allegations, since Simpson \"thinks he can do no wrong.\" \"He\\'s capable of stabbing people to death, so I think robbery is nothing surprising,\" she said. \"Normal, logical, civil-minded, law-abiding people don\\'t storm a room with guns demanding stuff back.\" Fromong had testified on Simpson\\'s behalf in the civil case, telling the court that prices for Simpson memorabilia had dropped substantially since the 1995 verdict. His testimony was part of the defense\\'s contention that Simpson could not afford to pay the Goldmans. Simpson recently wrote a book originally titled \"If I Did It\" and had planned to publish it himself, but a public outcry led to the cancellation of his book deal. A bankruptcy judge subsequently awarded the Goldmans the rights to the book in light of their inability to collect the wrongful death award. The Goldmans retitled the book, \"If I Did It: Confessions of the Killer.\" That book just hit bookstores. E-mail to a friend . CNN\\'s Ted Rowlands contributed to this report.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f61e68-b707-4270-8055-da0c24a09175",
   "metadata": {},
   "source": [
    "* 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95444a5-f492-407b-8343-95958bb3c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bail for ex-NFL star accused of directing men in alleged armed robbery .\n",
      "Simpson faces charges of robbery, assault, burglary and conspiracy .\n",
      "Alleged robbery involved sports-related items, police say .\n",
      "Simpson arrested Sunday in Las Vegas, but he says items were his .\n"
     ]
    }
   ],
   "source": [
    "print(sample['highlights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408963b8-bd80-401d-981f-00e0ae27ba6f",
   "metadata": {},
   "source": [
    "## 6.2. 텍스트 요약 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0ef2a5-0485-4002-b1f7-effa2e86c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973d6685-9ecc-4a27-909f-0bfd3e9f9166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4c913-74de-479f-9232-946c7135194b",
   "metadata": {},
   "source": [
    "* nltk의 문장 분리 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9544beab-a0e9-4e41-9495-71f4a5eb6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3c03e2-5e64-4588-9323-c5be05a8f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf081697-f89c-495d-928a-e1c649778db1",
   "metadata": {},
   "source": [
    "* transformer 모델에 넣기에는 너무 기니까, 문장 일부 선택\n",
    "    * 문장을 분리하고, 2000 문자열을 넘지 않는 경우만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ae17b6-f657-4547-97fa-4f0f28326492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7108b9-cae8-4cc0-b51f-5fc3ee75594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenize(sample['article']) # 문장 분리\n",
    "sents_len_sum = np.cumsum(list(map(len, sents)))\n",
    "last_idx = np.where(sents_len_sum < 2000)[0][-1].item() # 2000자 넘지 않는 문장까지 선택\n",
    "sample = ' '.join(sents[:last_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94fc9c-32a7-49a6-b601-808372ca53d5",
   "metadata": {},
   "source": [
    "### 6.2.1 요약 모델 베이스라인 - 첫 세 문장을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c088c39b-697b-40be-afe4-9b32c013d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d56d84-3b6c-458d-9b16-a59ade93ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d05c8087-244d-44de-ba52-853b2c1ce609",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['baseline'] = three_sentence_summary(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768901b2-73aa-488d-a6fd-f7d5e39f4621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS VEGAS, Nevada (CNN)  -- Former football star O.J.\n",
      "Simpson will be held without bail after his arrest on robbery and assault charges, police announced late Sunday.\n",
      "Police released this mug shot of O.J.\n"
     ]
    }
   ],
   "source": [
    "print(three_sentence_summary(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613f9d5-be63-40b3-b2c9-954cb0d33b9f",
   "metadata": {},
   "source": [
    "### 6.2.2 GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cedbba-f06b-420a-ac94-8a95fd5afc29",
   "metadata": {},
   "source": [
    "* GPT 모델을 요약 task에 활용하는 방법은 실제 글의 요약의 서두에 많이 쓰이는 TL;DR을 샘플 문장 뒤에 붙여서 summarization을 생성으로 흉내내는 방법을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec4517e-186c-4a2b-aa2f-c437626740ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd299f-54ae-4779-b0aa-505c499952b5",
   "metadata": {},
   "source": [
    "* gpt-2로 생성된 문장을 보면 TL;DR 뒤에 요약으로 추정되는 문장이 생성된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04468e5e-009a-4b28-a58c-3636e8b0f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'LAS VEGAS, Nevada (CNN)  -- Former football star O.J. Simpson will be held without bail after his arrest on robbery and assault charges, police announced late Sunday. Police released this mug shot of O.J. Simpson after his arrest. Simpson is accused of having directed several other men in an alleged armed robbery of sports memorabilia in a room at a Las Vegas hotel room. Las Vegas authorities said they have no information leading them to believe Simpson was carrying a firearm during the alleged incident at the Palace Station Hotel and Casino. Police said Simpson and other men burst into the room and walked out with the memorabilia, including some that was unrelated to Simpson, police said. \"We don\\'t believe that anyone was roughed up, but there were firearms involved,\" Lt. Clint Nichols told reporters. Nichols said the firearms were pointed at the victims. A reporter asked Nichols: Was \"O.J. was the boss in that room?\" Nichols responded, \"That is what we believe, yes.\" Watch Simpson transferred Sunday in handcuffs » . The alleged victims were identified as Bruce Fromong, a sports memorabilia collector who described the incident as \"a home invasion-type robbery,\" and Alfred Beardsley, who has been quoted by celebrity Web site TMZ.com as saying that Simpson later apologized to him and told him he regretted the incident. Acting on a tip, police met over the weekend at McCarran International Airport with 46-year-old Walter Alexander, of Mesa, Arizona, who told them about the alleged robbery and validated the tipster\\'s information, Capt. James Dillon told reporters. Alexander was arrested Saturday night on two counts of robbery with a deadly weapon, two counts of assault with a deadly weapon, conspiracy to commit robbery and burglary with a deadly weapon.\\nTL;DR:\\nMan arrested at airport in connection with OJ Simpson robbery. I don\\'t see anything illegal; I see something very peculiar.\\nWe\\'re in Vegas at the airport here now. And when we see somebody at McCarran International with a bunch of guns, it really gets our juices flowing.\\n[on air]: Yeah, a lot of people have said it\\'s like somebody got out of their room in a big rush of cocaine or something.\\n[on air] The TSA are having a bit of a meltdown right now with the incident. Not from me, but I do get it a lot. A lot of people are in shock. But for the most part, what people are saying is, \"What'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_query = sample + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "pipe_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164d987-1aeb-4682-ba37-ba251260424b",
   "metadata": {},
   "source": [
    "* 불완전 생성으로 추정되는 마지막 문장은 제외하고, 제대로 생성된 문장만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4e8d12-6aef-4ca9-a923-932e6a8a1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query):])[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08374d2-5d83-46b8-ad1c-12394321242e",
   "metadata": {},
   "source": [
    "### 6.2.3 T5\n",
    "* t5는 pretrain을 할 때, 이미 요약관련 task를 학습했음.\n",
    "* `summarize: ~~~` 형태로 문장을 넣게 되면 요약을 해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206d44e6-78a4-4b54-8690-ffa277308ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cb631-ee18-41f0-ad5a-f539bc8218c6",
   "metadata": {},
   "source": [
    "### 6.2.4. Bart\n",
    "* bart는 손상된 문장을 복원하는 능력이 뛰어남.\n",
    "* 요약도 일종의 저런 느낌으로 생각하고 fine-tune 가능. \n",
    "* cnndm으로 fine-tune된 모델 사용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b29fb61-097b-4e7a-9add-3404d27ec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c6a61-aefa-4e11-a0ea-47c791ac8518",
   "metadata": {},
   "source": [
    "### 6.2.5. Pegasus\n",
    "* 텍스트 요약에서 좋은 성능을 얻기위한 목적으로 사전학습을 진행함.\n",
    "* 실제 Donwstream Task에서 좋은 성능을 보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3dafb97-ace0-448b-82c6-4c30c4d768a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2ce1d-84de-4005-a6b5-80fc8a87490a",
   "metadata": {},
   "source": [
    "## 6.3. 요약 결과 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a8c14-4b07-41d5-bc0d-e260b9a6ec9f",
   "metadata": {},
   "source": [
    "* 정성적으로 GPT-2 이외의 다른 요약모델의 결과는 그럴 듯 함을 알 수 있다.\n",
    "* PEGASUS가 가장 훌륭함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7537ab5-7449-4798-ae78-70454adda6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "No bail for ex-NFL star accused of directing men in alleged armed robbery .\n",
      "Simpson faces charges of robbery, assault, burglary and conspiracy .\n",
      "Alleged robbery involved sports-related items, police say .\n",
      "Simpson arrested Sunday in Las Vegas, but he says items were his .\n",
      "\n",
      "BASELINE\n",
      "LAS VEGAS, Nevada (CNN)  -- Former football star O.J.\n",
      "Simpson will be held without bail after his arrest on robbery and assault charges, police announced late Sunday.\n",
      "Police released this mug shot of O.J.\n",
      "\n",
      "GPT2\n",
      "Man arrested at airport in connection with OJ Simpson robbery.\n",
      "I don't see anything illegal; I see something very peculiar.\n",
      "We're in Vegas at the airport here now.\n",
      "And when we see somebody at McCarran International with a bunch of guns, it really gets our juices flowing.\n",
      "[on air]: Yeah, a lot of people have said it's like somebody got out of their room in a big rush of cocaine or something.\n",
      "[on air] The TSA are having a bit of a meltdown right now with the incident.\n",
      "Not from me, but I do get it a lot.\n",
      "A lot of people are in shock.\n",
      "\n",
      "T5\n",
      "former football star accused of directing others in alleged armed robbery .\n",
      "police say they have no information leading them to believe he was carrying a firearm .\n",
      "alleged victims identified as Bruce Fromong and Alfred Beardsley .\n",
      "\n",
      "BART\n",
      "O.J.\n",
      "Simpson will be held without bail after his arrest on robbery charges.\n",
      "Simpson accused of directing several other men in an alleged armed robbery.\n",
      "Las Vegas authorities say they have no information leading them to believe Simpson was carrying a firearm.\n",
      "Police: Simpson and other men burst into the room and walked out with the memorabilia.\n",
      "\n",
      "PEGASUS\n",
      "Former football star O.J. Simpson will be held without bail, police say.\n",
      "Simpson accused of directing men in alleged armed robbery of sports memorabilia.\n",
      "Police say they have no information leading them to believe Simpson was carrying a firearm.\n",
      "Alleged victims identified as Bruce Fromong and Alfred Beardsley .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][20][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c547bf7c-c23a-4a21-8dbf-538e82ff24af",
   "metadata": {},
   "source": [
    "## 6.4. 생성된 텍스트 품질 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99696dcb-c6ef-4361-b801-5d0d537f243a",
   "metadata": {},
   "source": [
    "### 6.4.1 BLEU\n",
    "* 생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 단어 또는 n-gram이 존재하는가?\n",
    "* BLEU는 정밀도를 근간으로 하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bf063-c1a4-4c0c-858f-b242462027a3",
   "metadata": {},
   "source": [
    "* BLEU 값과 precision의 차이\n",
    "* 예시\n",
    "    * GT: `the cat is on the mat`\n",
    "    * GP: `the the the the the the`\n",
    "\n",
    "* vanila precision\n",
    "    * (실제 정답 유무 / 모델의 예측 값) = 6 / 6 = 1\n",
    "    * 실제 모델의 성능을 높게 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41518c-1bc8-4244-946c-b87b5a3a39c6",
   "metadata": {},
   "source": [
    "* __modified precision__\n",
    "    * (실제 정답 유무 clip(실제 정답 개수만) / 모델의 예측 값) = 2 / 6 = 1/3\n",
    "    * 실제 reference에 있는 이상의 키워드가 의도치 않게 precision을 높히는 것을 방지할 수 있음.\n",
    "\n",
    "$$p_n = {\\sum_{n-gram \\in snt} Count_{clip}(n-gram) \\over \\sum_{n-gram \\in snt} Count(n-gram)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46458e14-671c-4618-aab6-f17ab8dd89c4",
   "metadata": {},
   "source": [
    "* __modified precision for C sent__\n",
    "    * 1 prediction에 대한 C개의 정답셋이 있으므로 평균\n",
    "\n",
    "$$p_n = {\\sum_{snt \\in C} \\sum_{n-gram \\in snt} Count_{clip}(n-gram) \\over \\sum_{snt \\in C} \\sum_{n-gram \\in snt} Count(n-gram)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bf100-c218-4a8c-821d-033e629cb3f5",
   "metadata": {},
   "source": [
    "* 하지만 위의 문제는 재현율울 고려하지 않기 때문에 짧지만 정밀하게 생성된 시퀀스가 긴 문장보다 유리함.\n",
    "    *  짧은 애들을 penalty를 주기 위해, brevity penalty를 부여\n",
    "    * 생성된 문장이 원래 문장보다 짧을 경우에만 penalty 부여    \n",
    "$$BR = min(1, e^{1 - {l_{ref} \\over l_{gen} }  })$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e1de1d-d6ef-47bd-b542-a51e37c5527d",
   "metadata": {},
   "source": [
    "* BLEU 정리하면...\n",
    "    * 1, N그램까지 수정 정밀도의 기하평균\n",
    "    * 주로 BLEU-4가 많이 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ce02e-cf6f-4d3a-a7a5-bd99264bf0df",
   "metadata": {},
   "source": [
    "$$BLEU-N = BR \\times (\\prod^N_{n=1} p_n)^{1 \\over N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31368058-a466-41e7-a1ef-9141c9c45d33",
   "metadata": {},
   "source": [
    "**BLEU 한계**\n",
    "* 동의어를 고려하지 않음.\n",
    "* 다른 한계는 여기 참고\n",
    "  * https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
    "* 토큰화된 텍스트를 기대 \n",
    "  * SacreBLEU 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86d24e-1099-41a7-81ca-74f96e77d3d2",
   "metadata": {},
   "source": [
    "### BLEU 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ed40e1-55fa-45d5-a32c-016c95007842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221950/536429031.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d2346d-44f0-4722-8481-f2d18f35875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e127ed56-097c-4f42-8096-7a65c18b3ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc3d1fdb-3419-481e-b1c3-612081eb4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a6df3-9e7c-4464-b8c7-c65b46469fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0b2aa-e6b0-4e7c-aa9f-cc9c03d0be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "* \n",
    "\n",
    "    * 단순 Precision - (실제 정답에 존재하 유무 / 모델의 예측값)\n",
    "    * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac180da-6b61-45a7-96b3-221d2673c390",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a3351f-e22c-4307-b269-6d15b6e77b4c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139de0f-6a85-49d3-8e0c-912652b5976d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 궁금.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0303f0-cdc8-44a3-86aa-da9377542bed",
   "metadata": {},
   "source": [
    "* Abstractive Extraction과 Summarization의 task의 차이? 용어만 다른건가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165b49c-5bad-45ea-9457-4a9559163fe0",
   "metadata": {},
   "source": [
    "* Summarization은 주로 하나의 context가 긴 하나의 문서(document)를 요약하는 것인데, 여러 짧은 sentence를 요약하는 것도 동일한 방식으로 해결할 수 있나?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e4498-19ba-46c0-ac19-dd9597e5515d",
   "metadata": {},
   "source": [
    "* BLEU의 한계를 p.208에서 유도된 식의 많은 단계가 임시방편이고 깨지기 쉬움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23d4a4-d98e-4020-8bcc-b2f9312f6a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
